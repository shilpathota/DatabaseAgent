#database_agent.py
# -*- coding: utf-8 -*-
"""Database Agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h7lMckRXWpyEv1D6nWVMifrZd_-5qxYl

# Building Database Agent
1. Build basic AI agent using Langchain and Azure OpenAI
2. Interact with CSV data
3. Connecting to SQL database
4. Azure openAI Function Calling Feature
5. Leveraging Assistants API for SQL databases

## Build AI Agent
"""

# Uninstall any GPU-specific builds first
!pip uninstall -y torch torchvision torchaudio bitsandbytes

# Install latest stable CPU-only PyTorch
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Install Transformers + LangChain
!pip install -U "transformers>=4.43" accelerate
!pip install -U langchain langchain-huggingface

# put these two lines at the very top of the cell
import os
os.environ["TRANSFORMERS_NO_TORCHVISION"] = "1"

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline
from langchain.schema import HumanMessage, SystemMessage

MODEL_ID = "Qwen/Qwen2.5-0.5B-Instruct"   # model you chose

tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    device_map="cpu",            # force CPU
    torch_dtype=torch.float32,   # CPU runs best in float32
    trust_remote_code=True,
)

gen = pipeline(
    "text-generation",
    model=model,
    tokenizer=tok,
    max_new_tokens=128,
    do_sample=True,
)

# 1) Wrap HF pipeline as a LangChain LLM
hf_llm = HuggingFacePipeline(pipeline=gen)

"""## Read a CSV file with the data"""

import pandas as pd
df = pd.read_csv("./all-states-history.csv").fillna(value = 0)

!pip install langchain_experimental

from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

agent = create_pandas_dataframe_agent(
    llm=hf_llm,
    df=df,                                  # your existing DataFrame
    allow_dangerous_code=True,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    include_df_in_prompt=False,             # keep input small
    number_of_head_rows=0,
    max_iterations=4,
    max_execution_time=30,
    return_intermediate_steps=True,
    verbose=False,
    agent_executor_kwargs={"handle_parsing_errors": True},
)

CSV_PROMPT_PREFIX = """
First set the pandas display options to show all the columns,
get the column names, then answer the question.
"""

CSV_PROMPT_SUFFIX = """
- **ALWAYS** before giving the Final Answer, try another method.
Then reflect on the answers of the two methods you did and ask yourself
if it answers correctly the original question.
If you are not sure, try another method.
- If the methods tried do not give the same result,reflect and
try again until you have two methods that have the same result.
- If you still cannot arrive to a consistent result, say that
you are not sure of the answer.
- If you are sure of the correct answer, create a beautiful
and thorough response using Markdown.
- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,
ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.
- **ALWAYS**, as part of your "Final Answer", explain how you got
to the answer on a section that starts with: "\n\nExplanation:\n".
In the explanation, mention the column names that you used to get
to the final answer.
"""

QUESTION = "How may patients were hospitalized during July 2020"
"in Texas, and nationwide as the total of all states?"
"Use the hospitalizedIncrease column"

prompt = f"{CSV_PROMPT_PREFIX}\n{QUESTION}\n{CSV_PROMPT_SUFFIX}"
out = agent.invoke({"input": prompt})
print(out["output"])

"""## Connecting to SQL database"""

from sqlalchemy import create_engine

"""Move data to SQL"""

# Path to your SQLite database file
database_file_path = "./test.db"

# Create an engine to connect to the SQLite database
# SQLite only requires the path to the database file
engine = create_engine(f'sqlite:///{database_file_path}')
file_url = "./all-states-history.csv"
df = pd.read_csv(file_url).fillna(value = 0)
df.to_sql(
    'all_states_history',
    con=engine,
    if_exists='replace',
    index=False
)

MSSQL_AGENT_PREFIX = """

You are an agent designed to interact with a SQL database.
## Instructions:
- Given an input question, create a syntactically correct {dialect} query
to run, then look at the results of the query and return the answer.
- Unless the user specifies a specific number of examples they wish to
obtain, **ALWAYS** limit your query to at most {top_k} results.
- You can order the results by a relevant column to return the most
interesting examples in the database.
- Never query for all the columns from a specific table, only ask for
the relevant columns given the question.
- You have access to tools for interacting with the database.
- You MUST double check your query before executing it.If you get an error
while executing a query,rewrite the query and try again.
- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.)
to the database.
- DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS
OF THE CALCULATIONS YOU HAVE DONE.
- Your response should be in Markdown. However, **when running  a SQL Query
in "Action Input", do not include the markdown backticks**.
Those are only for formatting the response, not for executing the command.
- ALWAYS, as part of your final answer, explain how you got to the answer
on a section that starts with: "Explanation:". Include the SQL query as
part of the explanation section.
- If the question does not seem related to the database, just return
"I don\'t know" as the answer.
- Only use the below tools. Only use the information returned by the
below tools to construct your query and final answer.
- Do not make up table names, only use the tables returned by any of the
tools below.

## Tools:

"""

MSSQL_AGENT_FORMAT_INSTRUCTIONS = """

## Use the following format:

Question: the input question you must answer.
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}].
Action Input: the input to the action.
Observation: the result of the action.
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer.
Final Answer: the final answer to the original input question.

Example of Final Answer:
<=== Beginning of example

Action: query_sql_db
Action Input:
SELECT TOP (10) [death]
FROM covidtracking
WHERE state = 'TX' AND date LIKE '2020%'

Observation:
[(27437.0,), (27088.0,), (26762.0,), (26521.0,), (26472.0,), (26421.0,), (26408.0,)]
Thought:I now know the final answer
Final Answer: There were 27437 people who died of covid in Texas in 2020.

Explanation:
I queried the `covidtracking` table for the `death` column where the state
is 'TX' and the date starts with '2020'. The query returned a list of tuples
with the number of deaths for each day in 2020. To answer the question,
I took the sum of all the deaths in the list, which is 27437.
I used the following query

```sql
SELECT [death] FROM covidtracking WHERE state = 'TX' AND date LIKE '2020%'"
```
===> End of Example

"""

from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase

db = SQLDatabase.from_uri(f'sqlite:///{database_file_path}')
toolkit = SQLDatabaseToolkit(db=db, llm=hf_llm)

QUESTION = """How may patients were hospitalized during October 2020
in New York, and nationwide as the total of all states?
Use the hospitalizedIncrease column
"""

agent_executor_SQL = create_sql_agent(
    prefix=MSSQL_AGENT_PREFIX,
    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,
    llm=hf_llm,
    toolkit=toolkit,
    top_k=30,
    verbose=True
)

#Invoke SQL model
agent_executor_SQL.invoke(QUESTION)

"""Create Tools"""

import numpy as np
from sqlalchemy import text

def get_hospitalized_increase_for_state_on_date(state_abbr, specific_date):
    try:
        query = f"""
        SELECT date, hospitalizedIncrease
        FROM all_states_history
        WHERE state = '{state_abbr}' AND date = '{specific_date}';
        """
        query = text(query)

        with engine.connect() as connection:
            result = pd.read_sql_query(query, connection)
        if not result.empty:
            return result.to_dict('records')[0]
        else:
            return np.nan
    except Exception as e:
        print(e)
        return np.nan

def get_positive_cases_for_state_on_date(state_abbr, specific_date):
    try:
        query = f"""
        SELECT date, state, positiveIncrease AS positive_cases
        FROM all_states_history
        WHERE state = '{state_abbr}' AND date = '{specific_date}';
        """
        query = text(query)

        with engine.connect() as connection:
            result = pd.read_sql_query(query, connection)
        if not result.empty:
            return result.to_dict('records')[0]
        else:
            return np.nan
    except Exception as e:
        print(e)
        return np.nan

get_hospitalized_increase_for_state_on_date("AK","2021-03-05")

"""Execute function calling using SQL database"""

messages = [
    {"role": "system", "content": (
        "You MAY call tools. When you call a tool you MUST use the OpenAI tool-calling format: "
        "return tool_calls with function.name and function.arguments as a JSON string. "
        "Do NOT write tool calls in the message content, do NOT use <tool-use> tags, "
        "and do NOT use a 'parameters' field. Arguments keys must be: state_abbr, specific_date (YYYY-MM-DD)."
    )},
    {"role": "user", "content": "For AK on 2021-03-05, get the hospitalized increase."}
]

tools_sql = [
    {
        "type": "function",
        "function": {
            "name": "get_hospitalized_increase_for_state_on_date",
            "description": """Retrieves the daily increase in
                              hospitalizations for a specific state
                              on a specific date.""",
            "parameters": {
                "type": "object",
                "properties": {
                    "state_abbr": {
                        "type": "string",
                        "description": """The abbreviation of the state
                                          (e.g., 'NY', 'CA')."""
                    },
                    "specific_date": {
                        "type": "string",
                        "description": """The specific date for
                                          the query in 'YYYY-MM-DD'
                                          format."""
                    }
                },
                "required": ["state_abbr", "specific_date"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_positive_cases_for_state_on_date",
            "description": """Retrieves the daily increase in
                              positive cases for a specific state
                              on a specific date.""",
            "parameters": {
                "type": "object",
                "properties": {
                    "state_abbr": {
                        "type": "string",
                        "description": """The abbreviation of the
                                          state (e.g., 'NY', 'CA')."""
                    },
                    "specific_date": {
                        "type": "string",
                        "description": """The specific date for the
                                          query in 'YYYY-MM-DD'
                                          format."""
                    }
                },
                "required": ["state_abbr", "specific_date"]
            }
        }
    }
]

!pip install groq

from groq import Groq
from google.colab import userdata
import json

client = Groq(api_key=userdata.get("GROQ_API_KEY"))
model = "llama3-70b-8192"  # or "mixtral-8x7b-32768", etc.

response = client.chat.completions.create(
    model=model,
    messages=messages,
    tools=tools_sql,
    tool_choice="auto",
    temperature=0.0,
)
available_functions = {
    "get_positive_cases_for_state_on_date": get_positive_cases_for_state_on_date,
    "get_hospitalized_increase_for_state_on_date":get_hospitalized_increase_for_state_on_date
}
import re
msg = response.choices[0].message

tool_calls = msg.tool_calls or []
if not tool_calls and (msg.content or "").find("<tool-use>") != -1:
    m = re.search(r"<tool-use>(.*?)</tool-use>", msg.content, re.S)
    if m:
        blob = json.loads(m.group(1))
        for call in blob.get("tool_calls", []):
            name = call["function"]["name"]
            args = call.get("parameters", {})  # convert 'parameters' → arguments
            result = available_functions[name](**args)
            messages += [
                msg,
                {"role": "tool", "tool_call_id": call.get("id", "manual"), "content": str(result)}
            ]
        # then ask for the final answer
        final = client.chat.completions.create(model=model, messages=messages)
        print(final.choices[0].message.content)
else:
    print(msg.content)
# app.py
import os
os.environ["TRANSFORMERS_NO_TORCHVISION"] = "1"  # keep vision deps out of the import path

import io
import time
import pandas as pd
import streamlit as st

# LangChain bits (agent is created in the UI from your existing LLM)
from langchain.agents import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent


@st.cache_data(show_spinner=False)
def load_csv(file_bytes: bytes, sep: str, encoding: str, preview_rows: int = 300):
    df = pd.read_csv(io.BytesIO(file_bytes), sep=sep, encoding=encoding)
    # light normalization for friendlier queries
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    return df, df.head(min(preview_rows, len(df)))

st.set_page_config(page_title="Chat with your CSV", page_icon="📊", layout="wide")
st.title("📊 Chat with your CSV (LangChain)")

with st.sidebar:
    st.header("Agent settings")
    st.caption("Uses your existing `hf_llm` and builds a Pandas agent at runtime.")
    allow_dangerous = st.checkbox(
        "Allow Python execution (required by Pandas agent)",
        value=True,
        help="The Pandas DataFrame agent uses a Python REPL tool under the hood."
    )
    max_new_tokens = st.slider("Max new tokens (answer length)", 32, 1024, 256, 32)
    max_iterations = st.slider("Max agent iterations", 1, 12, 6, 1)
    max_exec_time = st.slider("Max execution time (sec)", 5, 120, 60, 5)
    st.divider()
    st.markdown("**LLM source:** `hf_llm` from `database_agent.py`")

st.markdown("### 1) Upload a CSV")
file = st.file_uploader("Drag & drop or browse", type=["csv"])
sep = st.text_input("Separator (optional)", value=",")
encoding = st.text_input("Encoding (optional)", value="utf-8")

df = None
if file:
    with st.spinner("Reading CSV…"):
        df, preview = load_csv(file.getvalue(), sep, encoding)
    st.success(f"Loaded {len(df):,} rows × {df.shape[1]} columns")
    with st.expander("Preview (first rows)"):
        st.dataframe(preview, use_container_width=True)

st.markdown("### 2) Ask a question")
default_q = "Filter to July 2020 and report the total hospitalizedIncrease for Texas and also the total across all states."
question = st.text_area("Natural-language question", value=default_q, height=90)

run = st.button("Run query", type="primary", disabled=(df is None or not question))

if run:
    if not allow_dangerous:
        st.error("The Pandas agent requires Python execution. Enable it in the sidebar.")
    elif df is None:
        st.error("Please upload a CSV first.")
    else:
        try:
            llm = hf_llm

            # ---- build the agent on-the-fly with your existing LLM ----
            agent = create_pandas_dataframe_agent(
                llm=llm,
                df=df,
                verbose=False,                    # keep the console clean
                allow_dangerous_code=True,        # required by this agent type
                include_df_in_prompt=False,       # prevents long prompts on big CSVs
                number_of_head_rows=0,
                max_iterations=max_iterations,
                max_execution_time=max_exec_time,
                early_stopping_method="generate",
                agent_executor_kwargs={"handle_parsing_errors": True},
                agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                return_intermediate_steps=False,
            )

            with st.spinner("Thinking…"):
                t0 = time.time()
                # Keep decoding deterministic by default (relies on your existing hf_llm config)
                result = agent.invoke({"input": question}, config={"callbacks": []})
                elapsed = time.time() - t0

            output = result["output"] if isinstance(result, dict) and "output" in result else result
            st.markdown("### 3) Answer")
            st.write(output)
            st.caption(f"Took {elapsed:.1f}s • Agent iterations ≤ {max_iterations}")

        except Exception as e:
            st.error(f"Run failed:\n\n{e}")
            if import_error:
                with st.expander("Import trace (database_agent.py)"):
                    st.code(import_error, language="text")
